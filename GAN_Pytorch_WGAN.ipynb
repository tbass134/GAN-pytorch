{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN - Pytorch - CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOQIkF39G3hGPKEpnikiQx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbass134/GAN-pytorch/blob/main/GAN_Pytorch_WGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRjXmllL4TjO"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tDv6byKQht0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f59a468f-cc4c-484d-c3dd-be8b2a54eab2"
      },
      "source": [
        "!pip install wandb -q\n",
        "\n",
        "import wandb\n",
        "wandb.init(project='cifar10-gan', entity='tbass134')\n",
        "config = wandb.config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtbass134\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/tbass134/cifar10-gan/runs/32p5bkrk\" target=\"_blank\">vibrant-frost-18</a></strong> to <a href=\"https://wandb.ai/tbass134/cifar10-gan\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy2BbrHa7Dnt"
      },
      "source": [
        "#used when not using wandb\n",
        "# class Config():\n",
        "#   def __init__(self):\n",
        "#     pass\n",
        "# config = Config()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIkIgW1t4wbg"
      },
      "source": [
        "class Critic(nn.Module): #aka discriminator\n",
        "  def __init__(self, channels_img, features_d):\n",
        "    super().__init__()\n",
        "    self.critic = nn.Sequential(\n",
        "        \n",
        "      nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      \n",
        "      nn.Conv2d(features_d, features_d*2, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "      nn.InstanceNorm2d(features_d*2, affine=True),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.Conv2d(features_d*2, features_d*4, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "      nn.InstanceNorm2d(features_d*4, affine=True,\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.Conv2d(features_d*4, features_d*8, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "      nn.InstanceNorm2d(features_d*8, affine=True),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.Conv2d(features_d*8, 1, kernel_size=4, stride=2, padding=0),\n",
        "      nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.critic(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, channels_noise, channels_img, features_g):\n",
        "    super().__init__()\n",
        "    self.gen = nn.Sequential(\n",
        "        \n",
        "        nn.ConvTranspose2d(channels_noise, features_g * 16, 4, 1, 0, bias=False),\n",
        "        nn.BatchNorm2d(features_g * 16),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.ConvTranspose2d( features_g * 16, features_g * 8, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(features_g * 8),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.ConvTranspose2d( features_g * 8, features_g * 4, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(features_g * 4),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.ConvTranspose2d( features_g * 4, features_g * 2, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(features_g * 2),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.ConvTranspose2d( features_g * 2, channels_img, 4, 2, 1),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "       \n",
        "  def forward(self, x):\n",
        "    return self.gen(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq2ba0QjLzig"
      },
      "source": [
        "def initialize_weights(model):\n",
        "    # Initializes weights according to the DCGAN paper\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
        "            nn.init.normal_(m.weight.data, 0.0, 0.02)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjMrhUY-uNSl",
        "outputId": "6870ba75-6d5e-4dc5-dae0-4fef3c699810"
      },
      "source": [
        "config.img_size = 64\n",
        "config.img_channels = 3\n",
        "\n",
        "tfs = transforms.Compose([\n",
        "                          transforms.Resize(config.img_size),\n",
        "                          transforms.ToTensor(),\n",
        "                          transforms.Normalize(\n",
        "                              [0.5 for _ in range(config.img_channels)],\n",
        "                              [0.5 for _ in range(config.img_channels)]\n",
        "                          )\n",
        "     ])\n",
        "dset = datasets.CIFAR10(root='.', train=True,download=True, transform=tfs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEBWSMQH6G1D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb31a720-08a4-4f0b-8ae9-38828be9b825"
      },
      "source": [
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "config.lr = 5e-5\n",
        "config.batch_size= 64\n",
        "config.noise_dim = 128\n",
        "config.num_epochs = 5\n",
        "config.features_critic = 64\n",
        "config.features_g = 64\n",
        "config.critic_iters = 5\n",
        "config.weight_clip = 0.01\n",
        "\n",
        "gen = Generator(config.noise_dim, config.img_channels, config.features_g).to(device)\n",
        "critic = Critic(config.img_channels, config.features_critic).to(device)\n",
        "initialize_weights(critic)\n",
        "initialize_weights(gen)\n",
        "\n",
        "# wandb.watch(gen, log=\"all\")\n",
        "# wandb.watch(critic, log=\"all\")\n",
        "#print(\"Generator\", gen)\n",
        "#print(\"Critic\", critic)\n",
        "\n",
        "fixed_noise = torch.randn(32, config.noise_dim, 1, 1).to(device)\n",
        "\n",
        "loader = DataLoader(dset, batch_size=config.batch_size, shuffle=True)\n",
        "\n",
        "opt_critic = optim.RMSprop(critic.parameters(), lr=config.lr)\n",
        "opt_gen = optim.RMSprop(gen.parameters(), lr=config.lr)\n",
        "\n",
        "gen.train()\n",
        "critic.train()\n",
        "step = 0\n",
        "\n",
        "for epoch in range(config.num_epochs):\n",
        "  for batch_idx, (real_images, real_labels) in enumerate(loader):\n",
        "    real_images = real_images.to(device)\n",
        "    cur_batch_size = real_images.shape[0]\n",
        "    # train descriminator\n",
        "\n",
        "    for _ in range(config.critic_iters):\n",
        "      #generate noise\n",
        "      noise = torch.randn(cur_batch_size, config.noise_dim, 1, 1).to(device)\n",
        "      fake_images = gen(noise)\n",
        "      critic_real = critic(real_images).reshape(-1)\n",
        "      critic_fake = critic(fake_images).reshape(-1)\n",
        "      loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))\n",
        "      critic.zero_grad()\n",
        "      loss_critic.backward(retain_graph=True)\n",
        "      opt_critic.step()\n",
        "\n",
        "      for p in critic.parameters():\n",
        "        p.data.clamp_(-config.weight_clip, config.weight_clip)\n",
        "\n",
        "    gen_fake = critic(fake_images).reshape(-1)\n",
        "    loss_gen = -torch.mean(gen_fake)\n",
        "    gen.zero_grad()\n",
        "    loss_gen.backward()\n",
        "    opt_gen.step()\n",
        "\n",
        "\n",
        "    if batch_idx % 100 == 0 and batch_idx > 0:\n",
        "        gen.eval()\n",
        "        critic.eval()\n",
        "        \n",
        "        losses = {\"loss_critic\": loss_critic, \"loss_g\":loss_gen}\n",
        "        print(losses)\n",
        "        wandb.log(losses)\n",
        "        print(\n",
        "            f\"Epoch [{epoch}/{config.num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
        "                  Loss Critic: {loss_critic:.4f}, loss G: {loss_gen:.4f}\"\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            fake = gen(noise)\n",
        "\n",
        "            \n",
        "            img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
        "            img_grid_real = torchvision.utils.make_grid(real_images[:32], normalize=True) \n",
        "            # show_img(img_grid_fake, f'{epoch}-fake')\n",
        "            # show_img(img_grid_real, f'{epoch}-real')\n",
        "\n",
        "            wandb.log({\"fake_images\": wandb.Image(img_grid_fake)})\n",
        "            wandb.log({\"real_images\": wandb.Image(img_grid_real)})\n",
        "\n",
        "        step += 1\n",
        "        gen.train()\n",
        "        critic.train()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss_critic': tensor(-56.7876, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.1556, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [0/5] Batch 100/782                   Loss Critic: -56.7876, loss G: 9.1556\n",
            "{'loss_critic': tensor(-57.1206, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.3518, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [0/5] Batch 200/782                   Loss Critic: -57.1206, loss G: 9.3518\n",
            "{'loss_critic': tensor(-57.1512, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.3524, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [0/5] Batch 300/782                   Loss Critic: -57.1512, loss G: 9.3524\n",
            "{'loss_critic': tensor(-57.1500, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.3565, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [0/5] Batch 400/782                   Loss Critic: -57.1500, loss G: 9.3565\n",
            "{'loss_critic': tensor(-57.1710, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.3618, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [0/5] Batch 500/782                   Loss Critic: -57.1710, loss G: 9.3618\n",
            "{'loss_critic': tensor(-57.1796, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.3644, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [0/5] Batch 600/782                   Loss Critic: -57.1796, loss G: 9.3644\n",
            "{'loss_critic': tensor(-57.2023, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.3951, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [0/5] Batch 700/782                   Loss Critic: -57.2023, loss G: 9.3951\n",
            "{'loss_critic': tensor(-57.2421, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.4193, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [1/5] Batch 100/782                   Loss Critic: -57.2421, loss G: 9.4193\n",
            "{'loss_critic': tensor(-57.2385, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.4202, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [1/5] Batch 200/782                   Loss Critic: -57.2385, loss G: 9.4202\n",
            "{'loss_critic': tensor(-57.2374, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.4192, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [1/5] Batch 300/782                   Loss Critic: -57.2374, loss G: 9.4192\n",
            "{'loss_critic': tensor(-57.2492, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.4193, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [1/5] Batch 400/782                   Loss Critic: -57.2492, loss G: 9.4193\n",
            "{'loss_critic': tensor(-57.2206, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.4024, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [1/5] Batch 500/782                   Loss Critic: -57.2206, loss G: 9.4024\n",
            "{'loss_critic': tensor(-57.2561, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.4212, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [1/5] Batch 600/782                   Loss Critic: -57.2561, loss G: 9.4212\n",
            "{'loss_critic': tensor(-57.2293, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.4216, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [1/5] Batch 700/782                   Loss Critic: -57.2293, loss G: 9.4216\n",
            "{'loss_critic': tensor(-57.2586, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.4238, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [2/5] Batch 100/782                   Loss Critic: -57.2586, loss G: 9.4238\n",
            "{'loss_critic': tensor(-57.2570, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.4232, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [2/5] Batch 200/782                   Loss Critic: -57.2570, loss G: 9.4232\n",
            "{'loss_critic': tensor(-57.2594, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.4261, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [2/5] Batch 300/782                   Loss Critic: -57.2594, loss G: 9.4261\n",
            "{'loss_critic': tensor(-57.0225, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.4031, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [2/5] Batch 400/782                   Loss Critic: -57.0225, loss G: 9.4031\n",
            "{'loss_critic': tensor(-56.9618, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.3442, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [2/5] Batch 500/782                   Loss Critic: -56.9618, loss G: 9.3442\n",
            "{'loss_critic': tensor(-57.0875, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.4429, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [2/5] Batch 600/782                   Loss Critic: -57.0875, loss G: 9.4429\n",
            "{'loss_critic': tensor(-57.0795, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.4307, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [2/5] Batch 700/782                   Loss Critic: -57.0795, loss G: 9.4307\n",
            "{'loss_critic': tensor(-57.0037, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.4156, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [3/5] Batch 100/782                   Loss Critic: -57.0037, loss G: 9.4156\n",
            "{'loss_critic': tensor(-56.9203, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.3985, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [3/5] Batch 200/782                   Loss Critic: -56.9203, loss G: 9.3985\n",
            "{'loss_critic': tensor(-56.8949, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.3865, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [3/5] Batch 300/782                   Loss Critic: -56.8949, loss G: 9.3865\n",
            "{'loss_critic': tensor(-56.6747, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.3529, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [3/5] Batch 400/782                   Loss Critic: -56.6747, loss G: 9.3529\n",
            "{'loss_critic': tensor(-56.3979, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.3142, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [3/5] Batch 500/782                   Loss Critic: -56.3979, loss G: 9.3142\n",
            "{'loss_critic': tensor(-57.0556, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.4437, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [3/5] Batch 600/782                   Loss Critic: -57.0556, loss G: 9.4437\n",
            "{'loss_critic': tensor(-56.9146, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.3870, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [3/5] Batch 700/782                   Loss Critic: -56.9146, loss G: 9.3870\n",
            "{'loss_critic': tensor(-57.2008, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.4962, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [4/5] Batch 100/782                   Loss Critic: -57.2008, loss G: 9.4962\n",
            "{'loss_critic': tensor(-56.8124, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.3701, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [4/5] Batch 200/782                   Loss Critic: -56.8124, loss G: 9.3701\n",
            "{'loss_critic': tensor(-56.8496, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.3584, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [4/5] Batch 300/782                   Loss Critic: -56.8496, loss G: 9.3584\n",
            "{'loss_critic': tensor(-57.0211, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.4176, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [4/5] Batch 400/782                   Loss Critic: -57.0211, loss G: 9.4176\n",
            "{'loss_critic': tensor(-56.0280, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.1646, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [4/5] Batch 500/782                   Loss Critic: -56.0280, loss G: 9.1646\n",
            "{'loss_critic': tensor(-56.2745, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.2241, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [4/5] Batch 600/782                   Loss Critic: -56.2745, loss G: 9.2241\n",
            "{'loss_critic': tensor(-55.3546, device='cuda:0', grad_fn=<NegBackward>), 'loss_g': tensor(9.1776, device='cuda:0', grad_fn=<NegBackward>)}\n",
            "Epoch [4/5] Batch 700/782                   Loss Critic: -55.3546, loss G: 9.1776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNZuouy2T7u-"
      },
      "source": [
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}